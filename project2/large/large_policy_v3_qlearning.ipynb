{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Policy v3: Q-Learning\n",
    "\n",
    "Given unknown `(s, a, r, sp)` data, find optimal policy. Not all `(s, a)` pairs will be seen in data, so interpolate from neighbors.\n",
    "- States: |S| = 302020\n",
    "- Actions: 9 actions\n",
    "- Discount factor = 0.95\n",
    "\n",
    "Lisa Fung\n",
    "\n",
    "Last Updated: 11/9/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_data = pd.read_csv(\"../data/large.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = 302020\n",
    "n_actions = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Q-learning to find action-value function $Q(s, a)$.\n",
    "- Run through data multiple times to update $Q(s, a) \\leftarrow Q(s, a) + \\alpha (r + \\gamma \\max_a Q(s', a') - Q(s, a))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timing function\n",
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "def time_it(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Function '{func.__name__}' executed in {elapsed_time:.6f} seconds\")\n",
    "        return result, elapsed_time\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time_it\n",
    "def q_learn(Q, data, iters=1, learning_rate=0.1, discount_rate=0.95):\n",
    "    for it in range(iters):\n",
    "        for i in range(len(data)):\n",
    "            s, a, r, sp = data.iloc[i]\n",
    "            Q[s, a] += learning_rate * (r + discount_rate * max(Q[sp, :]) - Q[s, a])\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_display(data, xdim, ydim, fig_title=None):\n",
    "    # data = data[1:, 1:].reshape((xdim, ydim, zdim))\n",
    "\n",
    "    fig, axes = plt.subplots(1, figsize=(20, 15), sharex=True, sharey=True)\n",
    "\n",
    "    # # Maximum, minimum value range for colorbar\n",
    "    # vmin, vmax = data.min(), data.max()\n",
    "\n",
    "    # for i in range(7):\n",
    "    #     img = axes[i].imshow(data[:, :, i], cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "    #     axes[i].set_title(f\"Action {i+1}\")\n",
    "\n",
    "    \n",
    "\n",
    "    # plt.tight_layout()\n",
    "    \n",
    "    img = axes.matshow(data[1:, 1:].reshape(xdim, ydim))#, cmap='viridis', vmin=0, vmax=1)\n",
    "    # plt.colorbar()\n",
    "    # plt.colorbar(img, ax=axes, fraction=0.046, pad=0.04, shrink=0.8)\n",
    "    cbar = fig.colorbar(img, ax=axes, orientation='vertical', fraction=0.05, pad=0.04)\n",
    "\n",
    "    if fig_title is not None:\n",
    "        plt.savefig(f\"{fig_title}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 'q_learn' executed in 2.147449 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.02764541, 0.14646395, ..., 0.3918645 , 0.87348761,\n",
       "         0.        ]]),\n",
       " 2.147449493408203)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = np.zeros((n_states + 1, n_actions + 1))\n",
    "q_learn(Q, large_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 'q_learn' executed in 63.910133 seconds\n",
      "Function 'q_learn' executed in 63.135728 seconds\n",
      "Function 'q_learn' executed in 62.553233 seconds\n",
      "Function 'q_learn' executed in 62.776709 seconds\n"
     ]
    }
   ],
   "source": [
    "# Store results: (iterations, learning_rate) : (Q, runtime)\n",
    "# Q_results = {}\n",
    "\n",
    "for n_iter in [30]:\n",
    "    for lr in [0.01, 0.05, 0.1, 0.2]:\n",
    "        Q = np.zeros((n_states + 1, n_actions + 1))\n",
    "        Q_results[(n_iter, lr)] = q_learn(Q, large_data, iters=n_iter, learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([302021, 302021, 302021, 302021, 302021, 302021, 302021, 302021,\n",
       "       302021, 302021])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.save(\"large_Q_function_sarsa_100iters.npy\", Q)\n",
    "# loaded_arr = np.load(\"large_Q_function_sarsa_100iters.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Policy from Q Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract optimal policy pi(s) = a from action-value function Q(s, a)\n",
    "\n",
    "def extract_policy(Q, mode='random'):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    policy = np.zeros(n_states+1)\n",
    "    # predicable_action = np.random.randint(1, n_actions+1)\n",
    "    # predicable_action = 4\n",
    "    for s in range(1, n_states+1):\n",
    "        policy[s] = np.argmax(Q[s, 1:])+1\n",
    "        # if policy[s] not in [1, 2, 3, 4]: # Actions [5,9] are usually 0, random\n",
    "        #     if mode == 'random':\n",
    "        #         policy[s] = np.random.randint(1, 5)\n",
    "        #     if mode == 'previous':\n",
    "        #         policy[s] = predicable_action\n",
    "        # else:\n",
    "        #     predicable_action = policy[s]\n",
    "\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.unique(optimal_policy_qlearn, return_counts=True)\n",
    "np.argmax([1, 2, 3][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write optimal policy to file\n",
    "def write_policy(policy, policy_name):\n",
    "    with open(f\"{policy_name}.policy\", \"w\") as file:\n",
    "        for a in policy[1:]:\n",
    "            file.write(f\"{int(a)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy from n_iters=30, lr=0.01:\n",
      "(array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]), array([     1, 301624,    108,    147,    124,      2,      1,      1,\n",
      "            1,     12]))\n",
      "\n",
      "Policy from n_iters=30, lr=0.05:\n",
      "(array([0., 1., 2., 3., 4., 5., 7., 8., 9.]), array([     1, 301654,    102,    117,    131,      1,      1,      1,\n",
      "           13]))\n",
      "\n",
      "Policy from n_iters=30, lr=0.1:\n",
      "(array([0., 1., 2., 3., 4., 5., 7., 9.]), array([     1, 301672,     91,    116,    125,      1,      1,     14]))\n",
      "\n",
      "Policy from n_iters=30, lr=0.2:\n",
      "(array([0., 1., 2., 3., 4., 5., 7., 9.]), array([     1, 301660,     97,    124,    123,      1,      2,     13]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# optimal_policy_qlearn = extract_policy(Q, mode='random')\n",
    "\n",
    "for (n_iters, lr), (Q, runtime) in Q_results.items():\n",
    "    if n_iters == 30:\n",
    "        policy = extract_policy(Q, mode='random')\n",
    "        print(f\"Policy from n_iters={n_iters}, lr={lr}:\")\n",
    "        print(np.unique(policy, return_counts=True))\n",
    "        print()\n",
    "        write_policy(policy, f\"large_qlearn_iters{n_iters}_lr{lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Q_results\n",
    "import pickle\n",
    "\n",
    "with open(\"large_qlearn_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(Q_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"large_qlearn_results.pkl\", \"rb\") as f:\n",
    "    loaded_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
