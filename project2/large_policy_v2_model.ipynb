{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Policy v2: Model-based approach\n",
    "\n",
    "Given unknown `(s, a, r, sp)` data, find optimal policy. Not all `(s, a)` pairs will be seen in data, so interpolate from neighbors.\n",
    "- States: |S| = 302020\n",
    "- Actions: 9 actions\n",
    "- Discount factor = 0.95\n",
    "\n",
    "Lisa Fung\n",
    "\n",
    "Last Updated: 11/9/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_data = pd.read_csv(\"./data/large.csv\")\n",
    "n_states = 302020\n",
    "n_actions = 9\n",
    "# n_limit_actions = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large Data Observations\n",
    "\n",
    "Rewards\n",
    "- Only 7 unique values: [-10  -5   0   5  10  50 100]\n",
    "- r=100 only at states sp = 301013, 301111, via actions [1,4]\n",
    "- sp = 301013\n",
    "    - s=301012, a=1 (delta_s = +1)\n",
    "    - s=301014, a=2 (delta_s = -1)\n",
    "    - s=301113, a=3 (delta_s = -100)\n",
    "    - s=300413, a=4 (delta_s = +600)\n",
    "- sp = 301111\n",
    "    - s=301110, a=1 (delta_s = +1)\n",
    "    - s=301112, a=2 (delta_s = -1)\n",
    "    - s=301211, a=3 (delta_s = -100)\n",
    "    - s=301011, a=4 (delta_s = +100)\n",
    "\n",
    "\n",
    "Actions\n",
    "- a = [1,4] are probabilistic\n",
    "- a = [5,9] are usually 0, occasionally random\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "\n",
    "- Transition Model: $T(s' - s \\mid a)$\n",
    "- Rewards: $R(s, s')$\n",
    "- Only take actions $a = 1,2,3,4,5$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transition Model\n",
    "\n",
    "$T(a, \\Delta s) = T(\\Delta s \\mid a)$\n",
    "- $|\\Delta s| = 9$, $|A| = 5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_data['delta_s'] = large_data['sp'] - large_data['s']  # delta_s = sp - s\n",
    "\n",
    "# Only keep delta_s for actions [1, 4] and 0\n",
    "# array([-600, -100,   -6,   -1,    0,    1,    6,  100,  600])\n",
    "delta_s_list = np.sort(large_data[large_data['a'] == 1]['delta_s'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 9)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_delta_s = 9\n",
    "n_limit_actions = 5\n",
    "\n",
    "T = np.zeros((n_limit_actions+1, n_delta_s))\n",
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_data_a_delta_s = large_data[large_data['delta_s'].isin(delta_s_list)][['a', 'delta_s']].value_counts().sort_index(level=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate transition counts\n",
    "for (a, delta_s), count in large_data_a_delta_s.items():\n",
    "    # row: ((a, delta_s), count)\n",
    "    if a <= n_limit_actions:\n",
    "        delta_s_idx = np.where(delta_s_list == delta_s)[0][0]\n",
    "        T[a, delta_s_idx] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisaf\\AppData\\Local\\Temp\\ipykernel_20080\\2452209420.py:2: RuntimeWarning: invalid value encountered in divide\n",
      "  T /= np.sum(T, axis=1, keepdims=True)\n"
     ]
    }
   ],
   "source": [
    "# Normalize along next state (sp) dimension to divide by N(s, a)\n",
    "T /= np.sum(T, axis=1, keepdims=True)\n",
    "T = np.nan_to_num(T, nan=0.0)   # convert nan to 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reward Model\n",
    "- $R(s, s')$ uniquely determines reward value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10,  -5,   0,   5,  10,  50, 100])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards_list = np.sort(large_data['r'].unique())\n",
    "rewards_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r in rewards_list[0:1]:\n",
    "#     print(f\"Reward r = {r}:\")\n",
    "#     print(large_data[large_data['r'] == r][['s', 'sp', 'a', 'r']].value_counts().sort_index())\n",
    "#     print(large_data[large_data['sp'] == 301112][['s', 'sp']].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine if any (s, sp) pair has different rewards\n",
    "# Answer: no. Reward is uniquely determined by R(s, sp)\n",
    "large_data_rewards = large_data.groupby(['s', 'sp'])\n",
    "large_data_rewards['r'].nunique().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_list = np.sort(large_data['s'].unique())\n",
    "n_seen_states = len(states_list)    # 500\n",
    "\n",
    "# R = np.zeros((n_seen_states, n_seen_states))\n",
    "R = large_data.pivot_table(index='s', columns='sp', values='r', aggfunc='first').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(100.0)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# large_data.pivot_table(index='sp', columns='s', values='r', aggfunc='first')[300413][301013]\n",
    "# # large_data[(large_data['s'] == 300413) & (large_data['sp'] == 301013)]\n",
    "\n",
    "# Check R indices\n",
    "test_s = 301014\n",
    "test_s_idx = np.where(states_list == test_s)[0][0]\n",
    "test_sp = 301013\n",
    "test_sp_idx = np.where(states_list == test_sp)[0][0]\n",
    "R[test_s_idx, test_sp_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_list = np.arange(1, n_limit_actions+1)\n",
    "actions_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value Iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finish Sunday 11/10!\n",
    "\n",
    "def value_iteration(U, n_iters=100, discount=0.95, threshold=1e-3):\n",
    "    # Update U with intermediate state updates instead of one iteration at a time\n",
    "    for i in range(n_iters):\n",
    "        residual = 0    # Maximum change in value among all U[s]\n",
    "        for s in range(len(states_list)):\n",
    "            max_Us = 0\n",
    "            for a in actions_list:\n",
    "                later_rewards = sum([T[a, delta_s] * U[sp] for delta_s_idx in range(1, n_states+1)])\n",
    "                # sp = s + delta_s\n",
    "                max_Us = max(max_Us, R[s] + discount * later_rewards)\n",
    "            residual = max(residual, abs(U[s] - max_Us))\n",
    "            U[s] = max_Us\n",
    "        if residual < threshold:\n",
    "            print(f\"Value iteration converged within threshold {threshold} at iteration {i}\\n\")\n",
    "            break\n",
    "    return U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Policy from Q Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract optimal policy pi(s) = a from action-value function Q(s, a)\n",
    "\n",
    "def extract_policy(Q, mode='random'):\n",
    "    \"\"\"\n",
    "    Limit only to actions 1-4.\n",
    "    \"\"\"\n",
    "    policy = np.zeros(n_states+1)\n",
    "    # predicable_action = np.random.randint(1, n_actions+1)\n",
    "    predicable_action = 4\n",
    "    for s in range(1, n_states+1):\n",
    "        policy[s] = np.argmax(Q[s, :])\n",
    "        if policy[s] not in [1, 2, 3, 4]: # Actions [5,9] are usually 0, random\n",
    "            if mode == 'random':\n",
    "                policy[s] = np.random.randint(1, 5)\n",
    "            if mode == 'previous':\n",
    "                policy[s] = predicable_action\n",
    "        else:\n",
    "            predicable_action = policy[s]\n",
    "\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Q' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m optimal_policy \u001b[38;5;241m=\u001b[39m extract_policy(\u001b[43mQ\u001b[49m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Q' is not defined"
     ]
    }
   ],
   "source": [
    "optimal_policy = extract_policy(Q, mode='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimal_policy_sarsa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39munique(\u001b[43moptimal_policy_sarsa\u001b[49m, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'optimal_policy_sarsa' is not defined"
     ]
    }
   ],
   "source": [
    "np.unique(optimal_policy, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write optimal policy to file\n",
    "with open(\"large.policy\", \"w\") as file:\n",
    "    for a in optimal_policy[1:]:\n",
    "        file.write(f\"{int(a)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Improvements\n",
    "\n",
    "- Average values of Q(s, a) with some distance-dependent discount for unvisited states s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
